{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import ttk\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thread Simulation Classes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyThread:\n",
    "    def __init__(self, target, args=()):\n",
    "        self.target = target\n",
    "        self.args = args\n",
    "\n",
    "    def start(self):\n",
    "        # Create a new thread and start it\n",
    "        thread = _Thread(target=self.target, args=self.args)\n",
    "        thread.start()\n",
    "\n",
    "class _Thread:\n",
    "    def __init__(self, target, args):\n",
    "        self.target = target\n",
    "        self.args = args\n",
    "\n",
    "    def start(self):\n",
    "        # Simulate starting a new thread by calling the target function\n",
    "        self.target(*self.args)\n",
    "\n",
    "    def join(self):\n",
    "        # Simulate joining a thread by waiting for the target function to finish\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Model Creation Function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=input_data.shape[1], activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Chunk of Data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_chunk(chunk, results, lock, result_text_widget):\n",
    "    input_data, output_data = chunk\n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "    model.fit(input_data, output_data, epochs=700, batch_size=30, verbose=0)\n",
    "\n",
    "    predictions = (model.predict(input_data) > 0.5).astype(float)\n",
    "    accuracy = accuracy_score(predictions, output_data)\n",
    "\n",
    "    with lock:\n",
    "        results.append((accuracy, predictions, output_data))\n",
    "        print(f\"Thread {time.thread_time_ns()} finished.\")\n",
    "\n",
    "        # Display evaluation matrix on the GUI\n",
    "        result_text_widget.insert(tk.END, \"\\nEvaluation Metrics:\\n\")\n",
    "        result_text_widget.insert(tk.END, print_evaluation_metrics(predictions, output_data))\n",
    "        result_text_widget.insert(tk.END, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing Evaluation Metrics:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_evaluation_metrics(predictions, output_data):\n",
    "    result = \"\"\n",
    "    result += \"Accuracy: \" + str(accuracy_score(predictions, output_data)) + \"\\n\"\n",
    "    result += \"Precision: \" + str(precision_score(predictions, output_data)) + \"\\n\"\n",
    "    result += \"Recall: \" + str(recall_score(predictions, output_data)) + \"\\n\"\n",
    "    result += \"F1 Score: \" + str(f1_score(predictions, output_data)) + \"\\n\"\n",
    "    result += \"Confusion Matrix:\\n\" + str(confusion_matrix(predictions, output_data)) + \"\\n\"\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    data = read_csv(file_path)\n",
    "    return data.values[:, :-1], data.values[:, -1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Processing Function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_processing():\n",
    "    global input_data, output_data\n",
    "    input_data, output_data = load_data()\n",
    "\n",
    "    # Data preprocessing\n",
    "    scaler = StandardScaler()\n",
    "    input_data = scaler.fit_transform(input_data)\n",
    "\n",
    "    num_threads = 4\n",
    "    data_chunks = list(zip(np.array_split(input_data, num_threads),\n",
    "                        np.array_split(output_data, num_threads)))\n",
    "\n",
    "    results = []\n",
    "    lock = MyThreadLock()\n",
    "\n",
    "    # GUI Setup\n",
    "    result_text = \"\\nOverall Evaluation Metrics:\\n\"\n",
    "    result_label.config(text=result_text)\n",
    "\n",
    "    # Display evaluation matrix on the GUI\n",
    "    result_text_widget.delete(1.0, tk.END)\n",
    "\n",
    "    # Train models in parallel\n",
    "    threads = []\n",
    "    for i, chunk in enumerate(data_chunks):\n",
    "        thread = MyThread(target=train_model_chunk, args=(chunk, results, lock, result_text_widget))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "\n",
    "    # Wait for all threads to finish\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "    # Combine results from all threads\n",
    "    combined_predictions = np.concatenate([result[1] for result in results])\n",
    "    combined_output_data = np.concatenate([result[2] for result in results])\n",
    "\n",
    "    # Print overall evaluation metrics\n",
    "    result_text += \"\\nOverall Evaluation Metrics:\\n\"\n",
    "    result_text += print_evaluation_metrics(combined_predictions, combined_output_data)\n",
    "    result_label.config(text=result_text)\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    keras_clf = KerasClassifier(build_fn=create_model, epochs=700, batch_size=30, verbose=0)\n",
    "    cv_predictions = cross_val_predict(keras_clf, input_data, output_data, cv=skf)\n",
    "\n",
    "    # Display cross-validation evaluation metrics on the GUI\n",
    "    result_text_widget.insert(tk.END, \"\\nCross-Validation Evaluation Metrics:\\n\")\n",
    "    result_text_widget.insert(tk.END, print_evaluation_metrics(cv_predictions, output_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MyThreadLock Class (Simulated Lock):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyThreadLock:\n",
    "    def __enter__(self):\n",
    "        pass\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUI Setup:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step\n",
      "Thread 9031250000 finished.\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Thread 13156250000 finished.\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Thread 18046875000 finished.\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Thread 23062500000 finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Program Files\\Python311\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\MEGA TECH\\AppData\\Local\\Temp\\ipykernel_13600\\4201420214.py\", line 32, in start_processing\n",
      "    thread.join()\n",
      "    ^^^^^^^^^^^\n",
      "AttributeError: 'MyThread' object has no attribute 'join'\n"
     ]
    }
   ],
   "source": [
    "# GUI Setup\n",
    "root = tk.Tk()\n",
    "root.title(\"Machine Learning GUI\")\n",
    "root.geometry(\"600x500\")  # Set initial window size\n",
    "\n",
    "# Set a custom style for ttk widgets\n",
    "style = ttk.Style()\n",
    "style.configure(\"TButton\", foreground=\"blue\", background=\"blue\", font=(\"Helvetica\", 12, \"bold\"))\n",
    "style.configure(\"TLabel\", font=(\"Helvetica\", 14, \"bold\"))\n",
    "\n",
    "load_button = ttk.Button(root, text=\"Load Data\", command=load_data)\n",
    "load_button.pack(pady=10)\n",
    "\n",
    "start_button = ttk.Button(root, text=\"Start Processing\", command=start_processing)\n",
    "start_button.pack(pady=10)\n",
    "\n",
    "result_label = ttk.Label(root, text=\"\")\n",
    "result_label.pack(pady=10)\n",
    "\n",
    "# Display evaluation matrix on the GUI\n",
    "result_text_widget = tk.Text(root, height=20, width=50)\n",
    "result_text_widget.pack(pady=10)\n",
    "\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
